#!/bin/bash
set -eo pipefail

# Dir setup
DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
. "${DIR}/common"
ROOT=$(dirname "${DIR}")

# Check if required tools are installed
has_tools kubectl pkill

# Cleanup function for graceful exit
cleanup() {
  echo "Cleaning up..."
  pkill -f "kubectl port-forward" || true
  rm -f /tmp/metrics.txt
}

# Set trap for cleanup on exit
trap cleanup EXIT

# Wait for nodes to be ready
kubectl wait --for=condition=Ready node --all --timeout=120s

# Tag worker nodes with GPU label
kubectl get nodes -l '!node-role.kubernetes.io/control-plane' -o name | \
  xargs -I {} kubectl label {} nodeGroup=gpu-worker --overwrite

# Create namespace if it doesn't exist
if ! kubectl get ns gpu-operator >/dev/null 2>&1; then
  kubectl create ns gpu-operator
fi

# Create config map for faker XML data
kubectl create cm smi-faker-data -n gpu-operator \
  --from-file=nvidia-smi.xml=etc/gpus/gb200.xml --dry-run=client -o yaml | \
  kubectl apply -f -

# Deploy fake nvidia-smi on all nodes with nodeGroup=gpu-worker label
kubectl apply -f deployments/smi-faker

# Wiat for all faker pods to be running
kubectl -n gpu-operator wait --for=condition=Ready pod -l app=nvidia-device-plugin-daemonset --timeout=120s

# Apply test deployment
kubectl apply -k deployments/gpuid/overlays/test

# Wait for the deployment to be available
kubectl wait --for=condition=available --timeout=60s deployment/gpuid -n gpuid 

# Wait for deployment pod to be running
kubectl rollout status deployment/gpuid -n gpuid --timeout=60s

# Print container imageID for debugging
IMAGE=$(kubectl get pods \
  -n gpuid \
  -l app=gpuid \
  -o jsonpath="{.items[0].status.containerStatuses[0].imageID}")
msg "Using image: $IMAGE"

# Count successful exports (length == number of nodes with GPUs)
SUCCESS_COUNT=$(kubectl -n gpuid logs -l app=gpuid --tail=-1 \
  | jq -s '[.[] | select(.msg == "export completed")] | length')
if [[ "$SUCCESS_COUNT" -lt 2 ]]; then
  err "Expected at least 2 successful export, found $SUCCESS_COUNT"
fi

# Verify node labels 

# Check SLSA provenance
msg "Verifying SLSA provenance..."
kubectl create namespace cosign-system
helm repo add sigstore https://sigstore.github.io/helm-charts
helm repo update
helm install policy-controller -n cosign-system sigstore/policy-controller --wait

# Label namespace for policy inclusion
kubectl label namespace gpuid policy.sigstore.dev/include=true --overwrite

# Apply image policy
kubectl apply -f deployments/policy/slsa-attestation.yaml

# Run a test pod to verify the image can be pulled and run
kubectl -n gpuid run test --image=$IMAGE

# Verify metrics are being exposed
msg "Checking metrics endpoint..."
kubectl port-forward -n gpuid service/gpuid 8080:8080 >/dev/null 2>&1 &
PF_PID=$!

# Wait for port-forward to establish
sleep 5

# Fetch metrics with timeout
echo "Fetching metrics..."
if timeout 10 curl -s "http://localhost:8080/metrics" > /tmp/metrics.txt; then
  msg "Successfully fetched metrics"
else
  err "ERROR: Failed to fetch metrics via port-forward"
fi

# Clean up test resources (handled by trap)
msg "Integration test passed"